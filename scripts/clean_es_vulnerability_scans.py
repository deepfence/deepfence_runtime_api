# Delete vulnerability scans for nodes
import argparse
import os
from collections import defaultdict

from elasticsearch import Elasticsearch

CUSTOMER_UNIQUE_ID = os.getenv('CUSTOMER_UNIQUE_ID', None)

ES_HOST = "%s://%s:%s" % (
    os.getenv('ELASTICSEARCH_SCHEME', 'http'),
    os.environ['ELASTICSEARCH_HOST'],
    os.environ['ELASTICSEARCH_PORT']
)

http_auth = None
if 'ELASTICSEARCH_USER' in os.environ:
    http_auth = (os.environ['ELASTICSEARCH_USER'],
                 os.environ['ELASTICSEARCH_PASSWORD'])

if http_auth:
    ES_CLIENT = Elasticsearch([ES_HOST], http_auth=http_auth, timeout=300)
else:
    ES_CLIENT = Elasticsearch([ES_HOST], timeout=300)


def get_rounding_time_unit(time_unit):
    rounding_time_unit = time_unit

    # For Month use Day as the rounding time unit.
    if time_unit == 'M' or time_unit == 'all':
        rounding_time_unit = 'd'
    return rounding_time_unit


class ESConn:
    @staticmethod
    def bulk_delete_query(index_name, body, wait_for_completion=False):
        ES_CLIENT.delete_by_query(index=index_name, body=body,
                                  wait_for_completion=wait_for_completion)

    @staticmethod
    def aggregation_helper(index_name, filters, aggs, number=None, time_unit=None,
                           lucene_query_string=None, add_masked_filter=True, get_only_query=False):
        should_objects = []
        range_query = None
        if number and time_unit and time_unit != 'all':
            rounding_time_unit = get_rounding_time_unit(time_unit)
            range_query = {
                "range": {
                    "@timestamp": {
                        "gt": "now-{0}{1}/{2}".format(number, time_unit, rounding_time_unit)
                    }
                }
            }
        lucene_query = None
        if lucene_query_string:
            lucene_query = {
                "query_string": {
                    "query": lucene_query_string
                }
            }
        and_terms = []
        if add_masked_filter:
            and_terms.append({
                "term": {
                    "masked.keyword": "false"
                }
            })
        if not filters:
            filters = {}
        for key, value in filters.items():
            if type(value) is not list:
                value = [value]
            if value:
                and_terms.append({"terms": {key + ".keyword": value}})
        if range_query:
            and_terms.append(range_query)
        if lucene_query:
            and_terms.append(lucene_query)
        should_objects.append({
            "bool": {
                "must": and_terms
            }
        })
        aggs_query = {
            "query": {
                "constant_score": {
                    "filter": {
                        "bool": {
                            "should": should_objects
                        }
                    }
                }
            },
            "aggs": aggs,
            "size": 0
        }
        if get_only_query:
            return aggs_query
        else:
            return ES_CLIENT.search(index=index_name, body=aggs_query)


CVE_INDEX = "cve"
CVE_SCAN_INDEX = "cve-scan"
SBOM_INDEX = "sbom-cve-scan"
SBOM_ARTIFACT_INDEX = "sbom-artifact"
if CUSTOMER_UNIQUE_ID:
    CVE_INDEX += f"-{CUSTOMER_UNIQUE_ID}"
    CVE_SCAN_INDEX += f"-{CUSTOMER_UNIQUE_ID}"
    SBOM_INDEX += f"-{CUSTOMER_UNIQUE_ID}"
    SBOM_ARTIFACT_INDEX += f"-{CUSTOMER_UNIQUE_ID}"


def get_top_n_scans_per_node(n):
    aggs = {
        "node_id": {
            "terms": {
                "field": "node_id.keyword",
                "size": "65536"
            },
            "aggs": {
                "scan_id": {
                    "top_hits": {
                        "sort": [
                                {
                                    "@timestamp": {
                                        "order": "desc"
                                    }
                                }
                        ],
                        "_source": {
                            "includes": [
                                "scan_id"
                            ]
                        },
                        "size": n
                    }
                }
            }
        }
    }
    resp = ESConn.aggregation_helper(
        CVE_SCAN_INDEX, {"action": "COMPLETED"}, aggs)
    node_id_map = defaultdict(list)
    for image_aggr in resp["aggregations"]["node_id"]["buckets"]:
        for scan_id_aggr in image_aggr.get("scan_id", {}).get("hits", {}).get("hits", []):
            node_id_map[image_aggr["key"]].append(scan_id_aggr["_source"]["scan_id"])
    return node_id_map


def delete_non_latest_scans(node_id_map):
    for node_id, scan_ids in node_id_map.items():

        print("keep node id: {} scan id: {}".format(node_id, scan_ids))

        body = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"cve_container_image.keyword": node_id}}
                    ],
                    "must_not": [
                        {"terms": {"scan_id.keyword": scan_ids}}
                    ]
                }
            }
        }

        # delete cve
        ESConn.bulk_delete_query(CVE_INDEX, body,
                                 wait_for_completion=True)

        body = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"node_id.keyword": node_id}}
                    ],
                    "must_not": [
                        {"terms": {"scan_id.keyword": scan_ids}}
                    ]
                }
            }
        }

        # delete sbom artifacts
        ESConn.bulk_delete_query(SBOM_ARTIFACT_INDEX, body,
                                 wait_for_completion=True)
        # delete sboms
        ESConn.bulk_delete_query(SBOM_INDEX, body,
                                 wait_for_completion=True)
        # delete vulnerability scans
        ESConn.bulk_delete_query(CVE_SCAN_INDEX, body,
                                 wait_for_completion=True)


def delete_older_than_days(days):
    body = {
        "query": {
            "range": {
                "@timestamp": {
                    "lte": "now-{}d".format(days)
                }
            }
        }
    }

    # delete sbom artifacts
    ESConn.bulk_delete_query(CVE_INDEX, body,
                             wait_for_completion=True)

    # delete sbom artifacts
    ESConn.bulk_delete_query(SBOM_ARTIFACT_INDEX, body,
                             wait_for_completion=True)
    # delete sboms
    ESConn.bulk_delete_query(SBOM_INDEX, body,
                             wait_for_completion=True)
    # delete vulnerability scans
    ESConn.bulk_delete_query(CVE_SCAN_INDEX, body,
                             wait_for_completion=True)


if __name__ == '__main__':
    parser = parser = argparse.ArgumentParser()
    parser.add_argument('--delete-by-days', default=False,
                        action='store_true', dest='delete_by_days')
    parser.add_argument('--scan-count', default='3', type=str,
                        action='store', dest='scan_count')
    parser.add_argument('--scan-days', default='90', type=str,
                        action='store', dest='scan_days')
    arguments = parser.parse_args()

    print('delete_by_days = {}'.format(arguments.delete_by_days))
    print('scan_count     = {}'.format(arguments.scan_count))
    print('scan_days      = {}'.format(arguments.scan_days))

    if not arguments.delete_by_days:
        print("deleting all scans keeping {} scans per node".format(
            arguments.scan_count))
        top_scans_node_id_map = get_top_n_scans_per_node(arguments.scan_count)
        delete_non_latest_scans(top_scans_node_id_map)
    else:
        print("deleting all vulnerability scans data older than {}days".format(
            arguments.scan_days))
        delete_older_than_days(arguments.scan_days)

